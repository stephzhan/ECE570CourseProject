{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stephzhan/ECE570CourseProject/blob/main/ECE570_Course_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > requirements.txt"
      ],
      "metadata": {
        "id": "BK1f9-E1A8KP"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "dcSsOfvevAwz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import time\n",
        "from typing import List, Dict\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "VFAeeKn3vCw-"
      },
      "outputs": [],
      "source": [
        "class LoraLayer(nn.Module):\n",
        "    def __init__(self, rank, in_dim, out_dim, alpha, dropout, merge_weights):\n",
        "        super().__init__()\n",
        "\n",
        "        self.alpha = alpha\n",
        "        if rank > 0:\n",
        "            self.A = torch.nn.Parameter(torch.empty((rank, in_dim)))\n",
        "            self.B = torch.nn.Parameter(torch.empty((out_dim, rank)))\n",
        "            self.scaling = self.alpha / rank\n",
        "\n",
        "        if dropout > 0.:\n",
        "            self.dropout = nn.Dropout(p=dropout)\n",
        "        else:\n",
        "            self.dropout = lambda x: x\n",
        "\n",
        "        self.merged = False\n",
        "        self.merge_weights = merge_weights\n",
        "\n",
        "        self.reset_parameters()\n",
        "        if device:\n",
        "            self.to(device)\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        nn.init.kaiming_uniform_(self.A, a=math.sqrt(5))\n",
        "        nn.init.zeros_(self.B)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.scaling * (self.dropout(x) @ self.A.T @ self.B.T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "NS3ZfR_mhb0D"
      },
      "outputs": [],
      "source": [
        "class LoraLinear(nn.Module):\n",
        "    def __init__(self, layer, rank, alpha, dropout, merge_weights):\n",
        "        super().__init__()\n",
        "\n",
        "        self.linear = layer\n",
        "        self.lora = LoraLayer(rank, self.linear.in_features, self.linear.out_features, alpha, dropout, merge_weights)\n",
        "        self.linear.weight.requires_grad = False\n",
        "        self.lora.reset_parameters()\n",
        "        self.linear.reset_parameters()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x) + self.lora(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LoraConv(nn.Module):\n",
        "    def __init__(self, layer, rank, alpha, dropout, merge_weights):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv = layer\n",
        "        k_size = self.conv.kernel_size\n",
        "        self.lora = LoraLayer(rank * k_size, self.conv.in_channels * k_size[0], self.conv.out_channels//self.conv.groups * k_size[1], alpha, dropout, merge_weights)\n",
        "        self.conv.weight.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "          return self.conv._conv_forward(x, self.conv.weight + (self.lora_B @ self.lora_A).view(self.conv.weight.shape) * self.scaling, self.conv.bias)"
      ],
      "metadata": {
        "id": "i3xE8Ms_-Syg"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LoraEmbedding(nn.Module):\n",
        "  def __init__(self, layer, rank, alpha, dropout, merge_weights):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = layer\n",
        "        self.lora = LoraLayer(rank, layer.num_embeddings, layer.embedding_dim, alpha, dropout, merge_weights)\n",
        "        self.embedding.weight.requires_grad = False\n",
        "\n",
        "  def forward(self, x):\n",
        "        pass"
      ],
      "metadata": {
        "id": "w9NmdQXMk1xW"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LoraMergedLinear(nn.Module):\n",
        "  def __init__(self, layer, rank, alpha, dropout, merge_weights):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = layer\n",
        "        self.lora = LoraLayer(rank, layer.num_embeddings, layer.embedding_dim, alpha, dropout, merge_weights)\n",
        "        self.embedding.weight.requires_grad = False\n",
        "\n",
        "  def forward(self, x):\n",
        "        pass"
      ],
      "metadata": {
        "id": "yvBl_Fsf3KjQ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "L9nb94nLheLJ"
      },
      "outputs": [],
      "source": [
        "## CODE REFERENCED FROM ECE570 ASSIGNMENT 3 ##\n",
        "\n",
        "def train(model: nn.Module,\n",
        "          loss_fn: nn.modules.loss._Loss,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          train_loader: torch.utils.data.DataLoader,\n",
        "          epoch: int=0)-> List:\n",
        "    model.train()\n",
        "    train_losses = []\n",
        "    train_counter = []\n",
        "\n",
        "    for batch_idx, (images, targets) in enumerate(train_loader):\n",
        "      images, targets = images.to(device), targets.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      output = model(images)\n",
        "      loss = loss_fn(output, targets)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      train_losses.append(loss.item())\n",
        "\n",
        "      if batch_idx % 100 == 0:\n",
        "        train_counter.append(\n",
        "        (batch_idx*len(images)) + ((epoch-1)*len(train_loader.dataset)))\n",
        "      torch.cuda.empty_cache()\n",
        "    assert len(train_losses) == len(train_loader)\n",
        "    return train_losses\n",
        "\n",
        "def test(model: nn.Module,\n",
        "         loss_fn: nn.modules.loss._Loss,\n",
        "         test_loader: torch.utils.data.DataLoader,\n",
        "         epoch: int=0)-> Dict:\n",
        "    model.eval()\n",
        "\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    test_stat = dict()\n",
        "    test_losses = []\n",
        "    test_counter = []\n",
        "    total_num = 0\n",
        "    pred_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for images, targets in test_loader:\n",
        "        images, targets = images.to(device), targets.to(device)\n",
        "        output = model(images)\n",
        "        test_loss += F.nll_loss(output, targets, reduction='sum').item()\n",
        "        pred = output.data.argmax(1) # we get the estimate of our result by look at the largest class value\n",
        "        correct += pred.eq(targets.data.view_as(pred)).sum() # sum up the corrected samples\n",
        "        pred_list.extend(list(pred))\n",
        "        total_num = total_num + 1\n",
        "\n",
        "      test_loss /= len(test_loader.dataset)\n",
        "      test_losses.append(test_loss)\n",
        "      test_counter.append(len(test_loader.dataset)*epoch)\n",
        "\n",
        "    test_stat['loss'] = test_loss\n",
        "    test_stat['accuracy'] = correct / len(test_loader.dataset)\n",
        "    test_stat['prediction'] = torch.Tensor(pred_list).to(torch.long)\n",
        "\n",
        "    print(f\"Test result on epoch {epoch}: Acc: {100*test_stat['accuracy']:.3f}%\")\n",
        "    return test_stat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqMTT_OPiukA",
        "outputId": "d462539c-221a-4be2-ec2a-8570900dc8a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "## CODE TAKEN FROM ECE570 ASSIGNMENT 3 ##\n",
        "train_transform = torchvision.transforms.Compose([torchvision.transforms.RandomResizedCrop(224),\n",
        "                                                  torchvision.transforms.RandomHorizontalFlip(),\n",
        "                                                  torchvision.transforms.ToTensor(),\n",
        "                                                  torchvision.transforms.Normalize((0.485,0.456,0.406), (0.229,0.224,0.225))])\n",
        "\n",
        "test_transform = torchvision.transforms.Compose([torchvision.transforms.Resize(256),\n",
        "                                                 transforms.CenterCrop(224),\n",
        "                                                  torchvision.transforms.ToTensor(),\n",
        "                                                  torchvision.transforms.Normalize((0.485,0.456,0.406), (0.229,0.224,0.225))])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10('data', train=True, download=True, transform=train_transform)\n",
        "test_dataset = torchvision.datasets.CIFAR10('data', train=False, download=True, transform=test_transform)\n",
        "\n",
        "batch_size_train, batch_size_test = 256, 512\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size_train, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size_test, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## CODE REFERENCED FROM ECE570 ASSIGNMENT 3 ##\n",
        "rank = [2, 4, 6, 8]\n",
        "max_epoch = 8\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for i in rank:\n",
        "  start = time.time()\n",
        "  resnet18_LORA = models.resnet18(pretrained=True)\n",
        "  resnet18_LORA.to(device)\n",
        "  resnet18_LORA.fc = LoraLinear(layer=resnet18_LORA.fc, rank=i, alpha=i, dropout=0.5, merge_weights=False)\n",
        "  optimizer = optim.SGD(resnet18_LORA.parameters(), lr=0.1, momentum=0.8)\n",
        "  for epoch in range(max_epoch):\n",
        "    train(resnet18_LORA, criterion, optimizer, train_loader, epoch)\n",
        "    test(resnet18_LORA, criterion, test_loader, epoch)\n",
        "  end = time.time()\n",
        "  print(f'Finished Training after {end-start} s ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXCz2Z7NOtWs",
        "outputId": "2428a864-3f9a-4378-c6dc-80dc97f2d8ec"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test result on epoch 0: Acc: 20.330%\n",
            "Test result on epoch 1: Acc: 48.970%\n",
            "Test result on epoch 2: Acc: 75.010%\n",
            "Test result on epoch 3: Acc: 80.500%\n",
            "Test result on epoch 4: Acc: 84.220%\n",
            "Test result on epoch 5: Acc: 85.800%\n",
            "Test result on epoch 6: Acc: 86.870%\n",
            "Test result on epoch 7: Acc: 90.660%\n",
            "Finished Training after 907.1683824062347 s \n",
            "Test result on epoch 0: Acc: 81.890%\n",
            "Test result on epoch 1: Acc: 87.590%\n",
            "Test result on epoch 2: Acc: 89.630%\n",
            "Test result on epoch 3: Acc: 91.440%\n",
            "Test result on epoch 4: Acc: 91.330%\n",
            "Test result on epoch 5: Acc: 91.140%\n",
            "Test result on epoch 6: Acc: 91.380%\n",
            "Test result on epoch 7: Acc: 92.710%\n",
            "Finished Training after 902.1033148765564 s \n",
            "Test result on epoch 0: Acc: 30.860%\n",
            "Test result on epoch 1: Acc: 42.360%\n",
            "Test result on epoch 2: Acc: 63.570%\n",
            "Test result on epoch 3: Acc: 75.820%\n",
            "Test result on epoch 4: Acc: 78.920%\n",
            "Test result on epoch 5: Acc: 80.470%\n",
            "Test result on epoch 6: Acc: 85.200%\n",
            "Test result on epoch 7: Acc: 86.520%\n",
            "Finished Training after 897.720733165741 s \n",
            "Test result on epoch 0: Acc: 10.000%\n",
            "Test result on epoch 1: Acc: 10.010%\n",
            "Test result on epoch 2: Acc: 23.170%\n",
            "Test result on epoch 3: Acc: 38.000%\n",
            "Test result on epoch 4: Acc: 49.970%\n",
            "Test result on epoch 5: Acc: 61.900%\n",
            "Test result on epoch 6: Acc: 70.330%\n",
            "Test result on epoch 7: Acc: 73.950%\n",
            "Finished Training after 899.6727440357208 s \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "ULBxdNLti10X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72c9b7ff-6d8c-4529-d506-214d0cd4c57c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test result on epoch 7: Acc: 30.720%\n",
            "Finished Training after 678.0140495300293 s \n",
            "Test result on epoch 7: Acc: 85.600%\n",
            "Finished Training after 677.3565816879272 s \n",
            "Test result on epoch 7: Acc: 91.400%\n",
            "Finished Training after 676.575676202774 s \n",
            "Test result on epoch 7: Acc: 82.410%\n",
            "Finished Training after 677.5734732151031 s \n"
          ]
        }
      ],
      "source": [
        "## CODE REFERENCED FROM ECE570 ASSIGNMENT 3 ##\n",
        "for i in rank:\n",
        "  start = time.time()\n",
        "  resnet18_FREEZE_LORA =  models.resnet18(pretrained=True)\n",
        "  resnet18_FREEZE_LORA.to(device)\n",
        "  for param in resnet18_FREEZE_LORA.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "  for param in resnet18_FREEZE_LORA.layer3.parameters():\n",
        "      param.requires_grad = True\n",
        "  for param in resnet18_FREEZE_LORA.layer4.parameters():\n",
        "      param.requires_grad = True\n",
        "  resnet18_FREEZE_LORA.fc = LoraLinear(layer=resnet18_FREEZE_LORA.fc, rank=i, alpha=i, dropout=0.5, merge_weights=False)\n",
        "  optimizer = optim.SGD([param for param in resnet18_FREEZE_LORA.parameters() if param.requires_grad], lr=0.1, momentum=0.8)\n",
        "  for epoch in range(max_epoch):\n",
        "    train(resnet18_FREEZE_LORA, criterion, optimizer, train_loader, epoch)\n",
        "  test(resnet18_FREEZE_LORA, criterion, test_loader, epoch)\n",
        "  end = time.time()\n",
        "  print(f'Finished Training after {end-start} s ')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_conv_with_lora(model, rank, alpha, dropout, merge_weights):\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, nn.Conv2d):\n",
        "            lora_layer = LoraConv(module, rank, alpha, dropout, merge_weights)\n",
        "            setattr(model, name, lora_layer)\n",
        "    return model"
      ],
      "metadata": {
        "id": "dluPNW_d5Z0N"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "kf0YTdHHlniN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ca1d064-d0fa-434e-d3a0-31e20fc0391f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "## CODE TAKEN FROM ECE570 ASSIGNMENT 3 ##\n",
        "\n",
        "resnet18_FT = models.resnet18(pretrained=True)\n",
        "resnet18_FT = resnet18_FT.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "zlJ6-yoD3EED",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c5770a9-789a-4461-da54-f2f94d748df1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test result on epoch 0: Acc: 80.140%\n",
            "Test result on epoch 1: Acc: 83.690%\n",
            "Test result on epoch 2: Acc: 86.080%\n",
            "Test result on epoch 3: Acc: 85.600%\n",
            "Test result on epoch 4: Acc: 87.000%\n",
            "Test result on epoch 5: Acc: 87.580%\n",
            "Test result on epoch 6: Acc: 88.520%\n",
            "Test result on epoch 7: Acc: 88.680%\n",
            "Finished Training after 902.0984711647034 s \n"
          ]
        }
      ],
      "source": [
        "## CODE TAKEN FROM ECE570 ASSIGNMENT 3 ##\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "max_epoch = 8\n",
        "optimizer = optim.SGD(resnet18_FT.parameters(), lr=0.1, momentum=0.8)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "for epoch in range(max_epoch):\n",
        "  train(resnet18_FT, criterion, optimizer, train_loader, epoch)\n",
        "  test(resnet18_FT, criterion, test_loader, epoch)\n",
        "\n",
        "end = time.time()\n",
        "print(f'Finished Training after {end-start} s ')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet18_FR = models.resnet18(pretrained=True)\n",
        "resnet18_FR = resnet18_FR.to(device)"
      ],
      "metadata": {
        "id": "pxw-gVbP8k1C"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "\n",
        "for param in resnet18_FR.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in resnet18_FR.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "for param in resnet18_FREEZE_LORA.layer3.parameters():\n",
        "    param.requires_grad = True\n",
        "for param in resnet18_FREEZE_LORA.layer4.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "max_epoch = 8\n",
        "optimizer = optim.SGD([param for param in resnet18_FR.parameters() if param.requires_grad], lr=0.1, momentum=0.8)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "for epoch in range(max_epoch):\n",
        "  train(resnet18_FR, criterion, optimizer, train_loader, epoch)\n",
        "  test(resnet18_FR, criterion, test_loader, epoch)\n",
        "\n",
        "end = time.time()\n",
        "print(f'Finished Training after {end-start} s ')"
      ],
      "metadata": {
        "id": "KGoh3rdrovzT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53fac1a7-2391-4bf1-c70e-64ae44383ab1"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test result on epoch 0: Acc: 56.870%\n",
            "Test result on epoch 1: Acc: 54.730%\n",
            "Test result on epoch 2: Acc: 68.700%\n",
            "Test result on epoch 3: Acc: 58.890%\n",
            "Test result on epoch 4: Acc: 68.540%\n",
            "Test result on epoch 5: Acc: 70.150%\n",
            "Test result on epoch 6: Acc: 56.500%\n",
            "Test result on epoch 7: Acc: 58.860%\n",
            "Finished Training after 779.1638870239258 s \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in rank:\n",
        "  start = time.time()\n",
        "  resnet18_TE = models.resnet18(pretrained=True)\n",
        "  resnet18_TE = resnet18_TE.to(device)\n",
        "\n",
        "  peft_config = LoraConfig(\n",
        "      task_type=\"IMAGE_CLASSIFICATION\",\n",
        "      r=i,\n",
        "      lora_alpha=i,\n",
        "      target_modules=[\"fc\"],\n",
        "      lora_dropout=0.5,)\n",
        "  resnet18_TE = get_peft_model(resnet18_TE, peft_config)\n",
        "  for param in resnet18_TE.layer3.parameters():\n",
        "      param.requires_grad = True\n",
        "  for param in resnet18_TE.layer4.parameters():\n",
        "      param.requires_grad = True\n",
        "\n",
        "  optimizer = optim.SGD(resnet18_TE.parameters(), lr=0.1, momentum=0.8)\n",
        "\n",
        "  for epoch in range(max_epoch):\n",
        "      train(resnet18_TE, criterion, optimizer, train_loader, epoch)\n",
        "  test(resnet18_TE, criterion, test_loader, epoch)\n",
        "  end = time.time()\n",
        "  print(f'Finished Training after {end - start} s ')"
      ],
      "metadata": {
        "id": "ib0hFZvIM6Ob",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77e6e23f-603c-4b62-829b-d307036698e0"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test result on epoch 7: Acc: 91.940%\n",
            "Finished Training after 677.086015701294 s \n",
            "Test result on epoch 7: Acc: 91.330%\n",
            "Finished Training after 678.5429043769836 s \n",
            "Test result on epoch 7: Acc: 91.720%\n",
            "Finished Training after 678.6246709823608 s \n",
            "Test result on epoch 7: Acc: 91.920%\n",
            "Finished Training after 678.3967809677124 s \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "authorship_tag": "ABX9TyOvu60Bg4lU3uzCUdojEjDE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}